#!/usr/bin/env bash

###############################################################################
# This script is used to perform TF-IDF as a sequence of 3 MapReduce jobs.
#
# Usage:
#    ./run_tfidf.sh <input_dir> <output_dir> [conf]
#  
#  where:
#     input_dir  = HDFS Directory with the input files
#     output_dir = HDFS Directory to place the output
#     conf       = Hadoop configuration options
#     songnum	 = Total number of songs
# This script will create three directories under <output_dir>, namely,
# tfidf1, tfidf2, and tfidf3, to place to output from each MR job.
#
# Examples:
#    ./run_tfidf.sh ~/input ~/output "-conf=myconf.xml" 20000
#    ./run_tfidf.sh ~/input ~/output "-Dmapred.reduce.tasks=2" 20000
#
# Author: Herodotos Herodotou
# Date: November 5, 2010
##############################################################################


# Make sure we have all the arguments
if [ $# -ne 5 ]; then
   printf "./run_tfidf.sh <input_dir> <output_dir> [conf] num\n"
   printf "   input_dir  = HDFS Directory with the input files\n"
   printf "   output_dir = HDFS Directory to place the output\n"
   printf "   conf       = Hadoop configuration options\n"
   printf "   songnum    = Num of song"
   exit -1
fi

# Get the input data
declare INPUT=$1;
declare OUTPUT=$2;
declare CONFIG=$3;
declare SONGNUM=$4;
declare REDUCENUM=$5;

# Remove the output directories
${HADOOP_HOME}/bin/hadoop fs -rmr $OUTPUT/tfidf1 >& /dev/null
${HADOOP_HOME}/bin/hadoop fs -rmr $OUTPUT/tfidf2 >& /dev/null
${HADOOP_HOME}/bin/hadoop fs -rmr $OUTPUT/tfidf3 >& /dev/null
${HADOOP_HOME}/bin/hadoop fs -rmr $OUTPUT/tfidf4 >& /dev/null

# Execute the jobs
printf "\nExecuting Job 1: Word Frequency in Doc\n"
${HADOOP_HOME}/bin/hadoop jar tfidf.jar tf-idf-1 $CONFIG $INPUT $OUTPUT/tfidf1 $REDUCENUM

printf "\nExecuting Job 2: Word Counts For Docs\n"
${HADOOP_HOME}/bin/hadoop jar tfidf.jar tf-idf-2 $CONFIG $OUTPUT/tfidf1 $OUTPUT/tfidf2 $REDUCENUM

printf "\nExecuting Job 3: Docs In Corpus and TF-IDF\n"
${HADOOP_HOME}/bin/hadoop jar tfidf.jar tf-idf-3 $CONFIG $INPUT $OUTPUT/tfidf2 $OUTPUT/tfidf3 $SONGNUM $REDUCENUM

printf "\nExecuting Job 4: Select keyword by TF-IDF\n"
${HADOOP_HOME}/bin/hadoop jar tfidf.jar tf-idf-4 $CONFIG $INPUT $OUTPUT/tfidf3 $OUTPUT/tfidf4 $SONGNUM $REDUCENUM

